{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61bb2911",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "\n",
    "1. Download [docker image](https://hub.docker.com/r/djstrong/krnnt2) of KRNNT2. It includes the following tools:\n",
    "\n",
    "\n",
    "    i. Morfeusz2 - morphological dictionary  \n",
    "    ii. Corpus2 - corpus access library\n",
    "    iii. Toki - tokenizer for Polish\n",
    "    iv. Maca - morphosyntactic analyzer   \n",
    "    v. KRNNT - Polish tagger\n",
    "\n",
    "2. As an alternative you can use Tagger interfaces in [Clarin-Pl](https://ws.clarin-pl.eu/tager.shtml)\n",
    "3. Use the tool to tag and lemmatize the law corpus.\n",
    "4. Using the tagged corpus compute bigram statistic for the tokens containing:\n",
    "\n",
    "\n",
    "    i. lemmatized, downcased word\n",
    "    ii. morphosyntactic **category** of the word (`subst`, `fin`, `adj`, etc.)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bebbcdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pl_PL.UTF-8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "import os\n",
    "import string\n",
    "import tarfile\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import operator\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "matplotlib.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "locale.setlocale(locale.LC_COLLATE, \"pl_PL.UTF-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886d9207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ma\\tnone']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lematyzacja to sprowadzanie danego słowa do jego formy podstawowej (hasłowej), która reprezentuje dany wyraz, np. wiórkami → wiórek, jeżdżący → jeździć,\n",
    "# tagging - the process of marking up a word in a text (corpus) as corresponding to a particular part of speech\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "r = requests.post('http://localhost:9200',data = \"ma. kota, i skacze:\")\n",
    "\n",
    "r.text.split(\"\\n\")[0:1]\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9737731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Token():\n",
    "    def __init__(self, lemma,morf,word) -> None:\n",
    "        self.word: string = word # kota\n",
    "        self.morf: string = morf\n",
    "        self.lemma: string = lemma # kot\n",
    "        self.flexeme : string = morf.split(\":\")[0] #morphosyntactic **category** of the word (`subst`, `fin`, `adj`, etc\n",
    "    \n",
    "\n",
    "\n",
    "def to_tokens(response):\n",
    "    lines = response.text.split('\\n')\n",
    "\n",
    "    tokens = []\n",
    "    token=None\n",
    "    morf=None\n",
    "    for line in lines:\n",
    "        if not line.startswith('\\t'):        \n",
    "            word = line.split('\\t')[0]\n",
    "        else:\n",
    "            lemma = line.split('\\t')[1]\n",
    "            if len(lemma.split(\" \")) > 1:\n",
    "                continue\n",
    "            morf = line.split('\\t')[2]\n",
    "            tokens.append(Token(lemma,morf,word))\n",
    "    return tokens\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fc1409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c3dec9d4f64473a7c7f314169a7044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1179.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "i = 0\n",
    "path = \"../data/ustawy\"\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for filename in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "        act = file.read()\n",
    "        act = regex.sub(r\"\\s+\", \" \", act)\n",
    "        act = regex.sub(r\"­\", \"\", act)\n",
    "        act = act.lower()\n",
    "\n",
    "        response = requests.post('http://localhost:9200',data = act.encode('utf-8'))\n",
    "        tokens+=to_tokens(response)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "#         if i==50:\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a65588ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(words):\n",
    "    words = zip(words, words[1:])\n",
    "    return [\" \".join(pair) for pair in words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b00e2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('artykuł .', 83635),\n",
       " ('ustęp .', 53430),\n",
       " ('pozycja .', 45054),\n",
       " (', pozycja', 42999),\n",
       " ('. 1', 39961)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [i.lemma   for i in tokens]\n",
    "gram2 = bigrams(text)\n",
    "\n",
    "# gram2 = [\n",
    "#     token\n",
    "#     for token in gram2\n",
    "#     if all(char not in string.punctuation and not char.isdigit() for char in token)\n",
    "# ]\n",
    "\n",
    "Counter(gram2).most_common(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4543391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adj interp', 335747),\n",
       " ('interp adj', 326954),\n",
       " ('prep subst', 323894),\n",
       " ('subst adj', 304685),\n",
       " ('subst subst', 283592)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [i.flexeme for i in tokens]\n",
    "gram2 = bigrams(text)\n",
    "\n",
    "# gram2 = [\n",
    "#     i\n",
    "#     for i in gram2\n",
    "#     if not \"interp\" in i\n",
    "# ]\n",
    "\n",
    "Counter(gram2).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502dd4a2",
   "metadata": {},
   "source": [
    "5. Discard bigrams containing characters other than letters. Make sure that you discard the invalid entries after computing the bigram counts.\n",
    "6. For example: \"Ala ma kota\", which is tagged as:\n",
    "\n",
    "   ```\n",
    "   Ala\tnone\n",
    "           Ala\tsubst:sg:nom:f\tdisamb\n",
    "   ma\tspace\n",
    "           mieć\tfin:sg:ter:imperf\tdisamb\n",
    "   kota\tspace\n",
    "           kot\tsubst:sg:acc:m2\tdisamb\n",
    "   .\tnone\n",
    "           .\tinterp\tdisamb\n",
    "   ```\n",
    "   \n",
    "   the algorithm should return the following bigrams: `ala:subst mieć:fin` and `mieć:fin kot:subst`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dc1efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(tokens,filtered=True):\n",
    "    token_pairs = zip(tokens, tokens[1:])\n",
    "    return [(i,j) for i,j in token_pairs]\n",
    "\n",
    "\n",
    "def isLetter(token):\n",
    "    return all(char not in string.punctuation and not char.isdigit() for char in token.word)\n",
    "\n",
    "    \n",
    "gram2 = bigrams(tokens)\n",
    "gram2 = [(i,j) for (i, j) in gram2 if isLetter(i) and isLetter(j) ]\n",
    "gram2_tokens = gram2\n",
    "gram2 = [f'{i.lemma}:{i.flexeme} {j.lemma}:{j.flexeme}' for (i, j) in gram2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd6d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gram2_count =Counter(gram2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "109aaa57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w:prep artykuł:brev', 31973),\n",
       " ('o:prep który:adj', 28658),\n",
       " ('który:adj mowa:subst', 28540),\n",
       " ('mowa:subst w:prep', 28473),\n",
       " ('w:prep ustęp:brev', 23501),\n",
       " ('z:prep dzień:subst', 11360),\n",
       " ('otrzymywać:fin brzmienie:subst', 10532),\n",
       " ('określić:ppas w:prep', 9781),\n",
       " ('do:prep sprawa:subst', 8718),\n",
       " ('ustawa:subst z:prep', 8625)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram2_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252c29e",
   "metadata": {},
   "source": [
    "7. Compute LLR statistic for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c84d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "token_count = defaultdict(int)\n",
    "\n",
    "for bigram, count in gram2_count.items():\n",
    "    (first_token, second_token) = bigram.split(\" \")\n",
    "    token_count[first_token] += count\n",
    "    token_count[second_token] += count\n",
    "\n",
    "total = sum(gram2_count.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6625f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(k):\n",
    "    N = np.sum(k)\n",
    "    return np.sum(k / N * np.ma.log(k / N).filled(0))\n",
    "\n",
    "\n",
    "def llr(a, b):\n",
    "\n",
    "    k11 = gram2_count[a + \" \" + b]\n",
    "    k12 = token_count[b] - k11\n",
    "    k21 = token_count[a] - k11\n",
    "    k22 = total - k21 - k12 - k11\n",
    "    k = np.array([[k11, k12], [k21, k22]])\n",
    "    rowSums = np.sum(k, axis=1).tolist()\n",
    "    colSums = np.sum(k, axis=0).tolist()\n",
    "\n",
    "    return 2 * np.sum(k) * (H(k) - H(rowSums) - H(colSums))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9fa101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2773291\n",
      "277329/2773291\n",
      "554658/2773291\n",
      "831987/2773291\n",
      "jak:prep na przykład:brev\n",
      "na przykład:brev kradzież:subst\n",
      "zgodny:adj to jest:brev\n",
      "1109316/2773291\n",
      "urząd:subst do spraw:brev\n",
      "budynek:subst na przykład:brev\n",
      "budynek:subst na przykład:brev\n",
      "nawóz:subst na przykład:brev\n",
      "na przykład:brev jeżeli:comp\n",
      "nawóz:subst na przykład:brev\n",
      "na przykład:brev nie:qub\n",
      "nawóz:subst na przykład:brev\n",
      "na przykład:brev w:prep\n",
      "nawóz:subst na przykład:brev\n",
      "na przykład:brev zawierawapniowego:adj\n",
      "częściowo:adv na przykład:brev\n",
      "na przykład:brev zawierać:pact\n",
      "nawóz:subst na przykład:brev\n",
      "na przykład:brev mało:adv\n",
      "nawóz:subst na przykład:brev\n",
      "na przykład:brev zawierać:pact\n",
      "nawóz:subst na przykład:brev\n",
      "na przykład:brev na:prep\n",
      "fosforowy:adj to jest:brev\n",
      "nawóz:subst na przykład:brev\n",
      "nawóz:subst na przykład:brev\n",
      "na przykład:brev nie:qub\n",
      "nawóz:subst na przykład:brev\n",
      "na przykład:brev jeżeli:comp\n",
      "nawóz:subst na przykład:brev\n",
      "na przykład:brev jeżeli:comp\n",
      "mgo:brev to jest:brev\n",
      "sód:subst to znaczy:brev\n",
      "zasadniczy:adj to znaczy:brev\n",
      "zuje:adj to znaczy:brev\n",
      "zasadniczy:adj to znaczy:brev\n",
      "jak:prep na przykład:brev\n",
      "1386645/2773291\n",
      "europejski:adj do spraw:brev\n",
      "sprawozdanie:subst roku bieżącego/bieżącym:brev\n",
      "sprawozdanie:subst roku bieżącego/bieżącym:brev\n",
      "1663974/2773291\n",
      "1941303/2773291\n",
      "lokacja:subst i tak dalej:brev\n",
      "jak:adv na przykład:brev\n",
      "elektryczny:adj na przykład:brev\n",
      "ściana:subst na przykład:brev\n",
      "2218632/2773291\n",
      "anorak:subst et cetera:brev\n",
      "anorak:subst et cetera:brev\n",
      "anorak:subst et cetera:brev\n",
      "anorak:subst et cetera:brev\n",
      "anorak:subst et cetera:brev\n",
      "anorak:subst et cetera:brev\n",
      "anorak:subst et cetera:brev\n",
      "anorak:subst et cetera:brev\n",
      "2495961/2773291\n"
     ]
    }
   ],
   "source": [
    "gram2_llr = {}\n",
    "length = len(gram2)\n",
    "i = 0\n",
    "for key in gram2:\n",
    "    if len(key.split()) > 2:\n",
    "        print(key)\n",
    "        continue\n",
    "    gram2_llr[key] = llr(*key.split())\n",
    "    if i % (int(length / 10)) == 0:\n",
    "        print(f\"{i}/{length}\")\n",
    "    # print(key,gram2_llr[key])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e9d56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('który:adj mowa:subst', 129911.44467048168),\n",
       " ('otrzymywać:fin brzmienie:subst', 104889.92928114616),\n",
       " ('o:prep który:adj', 98971.94897948248),\n",
       " ('w:prep w:prep', 90223.08575718079),\n",
       " ('w:prep artykuł:brev', 78823.4428443508),\n",
       " ('w:prep ustęp:brev', 63539.375680707126),\n",
       " ('mowa:subst w:prep', 50087.93290955135),\n",
       " ('dodawać:fin się:qub', 48767.67211949977),\n",
       " ('minister:subst właściwy:adj', 46342.51470052161),\n",
       " ('i:conj numer:brev', 42964.203399683334)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sort_dict(dictionary):\n",
    "    return dict(sorted(dictionary.items(), key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "\n",
    "gram2_llr = sort_dict(gram2_llr)\n",
    "list(gram2_llr.items())[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508869a8",
   "metadata": {},
   "source": [
    "8. Partition the entries based on the syntactic categories of the words, i.e. all bigrams having the form of \n",
    "   `w1:adj` `w2:subst` should be placed in one partition (the order of the words may not be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "548bcd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prep subst', 323768),\n",
       " ('subst subst', 280513),\n",
       " ('subst adj', 273635),\n",
       " ('adj subst', 188202),\n",
       " ('subst prep', 171068),\n",
       " ('subst conj', 84136),\n",
       " ('conj subst', 83096),\n",
       " ('ger subst', 81338),\n",
       " ('prep adj', 79664),\n",
       " ('prep brev', 66986)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gram2 = [f'{i.flexeme} {j.flexeme}' for (i, j) in gram2_tokens]\n",
    "top10 = Counter(gram2).most_common(10)\n",
    "top10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d36d8",
   "metadata": {},
   "source": [
    "9. Select the 10 largest partitions (partitions with the largest number of entries).\n",
    "10. Use the computed LLR measure to select 5 bigrams for each of the largest categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f93dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'otrzymywać:fin brzmienie:subst'\n",
    "def preprocess(string):\n",
    "    token1, token2= string.split(\" \")\n",
    "    return (token1.split(\":\"),token2.split(\":\"))\n",
    "\n",
    "def inCategory(string,category):\n",
    "    ([word1,flexeme1],[word2,flexeme2]) = preprocess(string)\n",
    "    return category == f\"{flexeme1} {flexeme2}\"\n",
    "\n",
    "\n",
    "# preprocess(string)[0][1]\n",
    "inCategory(string,\"fin subst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2af5c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prep subst</th>\n",
       "      <th>subst subst</th>\n",
       "      <th>subst adj</th>\n",
       "      <th>adj subst</th>\n",
       "      <th>subst prep</th>\n",
       "      <th>subst conj</th>\n",
       "      <th>conj subst</th>\n",
       "      <th>ger subst</th>\n",
       "      <th>prep adj</th>\n",
       "      <th>prep brev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z:prep dzień:subst 27379.07090054545</td>\n",
       "      <td>droga:subst rozporządzenie:subst 42326.6302884...</td>\n",
       "      <td>minister:subst właściwy:adj 46342.51470052161</td>\n",
       "      <td>który:adj mowa:subst 129911.44467048168</td>\n",
       "      <td>mowa:subst w:prep 50087.93290955135</td>\n",
       "      <td>mowa:subst i:conj 5933.002651984236</td>\n",
       "      <td>i:conj dzień:subst 3805.6834114623653</td>\n",
       "      <td>pozbawić:ger wolność:subst 10748.166422542694</td>\n",
       "      <td>o:prep który:adj 98971.94897948248</td>\n",
       "      <td>w:prep artykuł:brev 78823.4428443508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>na:prep podstawa:subst 24020.044894876017</td>\n",
       "      <td>skarb:subst państwo:subst 15173.809450670526</td>\n",
       "      <td>rzeczpospolita:subst polski:adj 29972.09246445966</td>\n",
       "      <td>następujący:adj zmiana:subst 14168.634295920887</td>\n",
       "      <td>ustawa:subst z:prep 15977.689100319558</td>\n",
       "      <td>dzień:subst i:conj 3462.6040641931695</td>\n",
       "      <td>i:conj ustawa:subst 3241.9459469478074</td>\n",
       "      <td>zasięgnąć:ger opinia:subst 8210.697539476629</td>\n",
       "      <td>w:prep który:adj 7387.952716919039</td>\n",
       "      <td>w:prep ustęp:brev 63539.375680707126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do:prep sprawa:subst 21141.5366789383</td>\n",
       "      <td>rada:subst minister:subst 10169.024629185624</td>\n",
       "      <td>samorząd:subst terytorialny:adj 17812.77131015857</td>\n",
       "      <td>niniejszy:adj ustawa:subst 13170.87462557446</td>\n",
       "      <td>dzień:subst w:prep 8702.908258365422</td>\n",
       "      <td>sprawa:subst i:conj 2868.6403303532406</td>\n",
       "      <td>i:conj sprawa:subst 3038.6657500358597</td>\n",
       "      <td>wykonywać:ger zawód:subst 4038.7485353954557</td>\n",
       "      <td>w:prep właściwy:adj 6000.002702112694</td>\n",
       "      <td>w:prep punkt:brev 7218.804944278644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>od:prep dzień:subst 18860.003016569382</td>\n",
       "      <td>ochrona:subst środowisko:subst 10093.641427783585</td>\n",
       "      <td>jednostka:subst organizacyjny:adj 17033.457473...</td>\n",
       "      <td>odrębny:adj przepis:subst 7728.815517471113</td>\n",
       "      <td>miesiąc:subst od:prep 7969.428312155529</td>\n",
       "      <td>przepis:subst i:conj 2673.388370419141</td>\n",
       "      <td>lub:conj dzień:subst 2179.500972628529</td>\n",
       "      <td>ograniczyć:ger wolność:subst 3909.855635819227</td>\n",
       "      <td>z:prep który:adj 4426.545214380086</td>\n",
       "      <td>z:prep późniejszy:brev 6559.177105338566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w:prep mowa:subst 14610.486845842592</td>\n",
       "      <td>terytorium:subst rzeczpospolita:subst 9974.156...</td>\n",
       "      <td>produkt:subst leczniczy:adj 16029.73146263255</td>\n",
       "      <td>walny:adj zgromadzenie:subst 7243.509665259683</td>\n",
       "      <td>ustawa:subst w:prep 7735.724017269629</td>\n",
       "      <td>ustawa:subst i:conj 2645.9153290615327</td>\n",
       "      <td>i:conj przepis:subst 2160.337295190103</td>\n",
       "      <td>zawrzeć:ger umowa:subst 3661.9406491424647</td>\n",
       "      <td>do:prep który:adj 2693.229605673264</td>\n",
       "      <td>do:prep artykuł:brev 3601.7646793204017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  prep subst  \\\n",
       "0       z:prep dzień:subst 27379.07090054545   \n",
       "1  na:prep podstawa:subst 24020.044894876017   \n",
       "2      do:prep sprawa:subst 21141.5366789383   \n",
       "3     od:prep dzień:subst 18860.003016569382   \n",
       "4       w:prep mowa:subst 14610.486845842592   \n",
       "\n",
       "                                         subst subst  \\\n",
       "0  droga:subst rozporządzenie:subst 42326.6302884...   \n",
       "1       skarb:subst państwo:subst 15173.809450670526   \n",
       "2       rada:subst minister:subst 10169.024629185624   \n",
       "3  ochrona:subst środowisko:subst 10093.641427783585   \n",
       "4  terytorium:subst rzeczpospolita:subst 9974.156...   \n",
       "\n",
       "                                           subst adj  \\\n",
       "0      minister:subst właściwy:adj 46342.51470052161   \n",
       "1  rzeczpospolita:subst polski:adj 29972.09246445966   \n",
       "2  samorząd:subst terytorialny:adj 17812.77131015857   \n",
       "3  jednostka:subst organizacyjny:adj 17033.457473...   \n",
       "4      produkt:subst leczniczy:adj 16029.73146263255   \n",
       "\n",
       "                                         adj subst  \\\n",
       "0          który:adj mowa:subst 129911.44467048168   \n",
       "1  następujący:adj zmiana:subst 14168.634295920887   \n",
       "2     niniejszy:adj ustawa:subst 13170.87462557446   \n",
       "3      odrębny:adj przepis:subst 7728.815517471113   \n",
       "4   walny:adj zgromadzenie:subst 7243.509665259683   \n",
       "\n",
       "                                subst prep  \\\n",
       "0      mowa:subst w:prep 50087.93290955135   \n",
       "1   ustawa:subst z:prep 15977.689100319558   \n",
       "2     dzień:subst w:prep 8702.908258365422   \n",
       "3  miesiąc:subst od:prep 7969.428312155529   \n",
       "4    ustawa:subst w:prep 7735.724017269629   \n",
       "\n",
       "                               subst conj  \\\n",
       "0     mowa:subst i:conj 5933.002651984236   \n",
       "1   dzień:subst i:conj 3462.6040641931695   \n",
       "2  sprawa:subst i:conj 2868.6403303532406   \n",
       "3  przepis:subst i:conj 2673.388370419141   \n",
       "4  ustawa:subst i:conj 2645.9153290615327   \n",
       "\n",
       "                               conj subst  \\\n",
       "0   i:conj dzień:subst 3805.6834114623653   \n",
       "1  i:conj ustawa:subst 3241.9459469478074   \n",
       "2  i:conj sprawa:subst 3038.6657500358597   \n",
       "3  lub:conj dzień:subst 2179.500972628529   \n",
       "4  i:conj przepis:subst 2160.337295190103   \n",
       "\n",
       "                                        ger subst  \\\n",
       "0   pozbawić:ger wolność:subst 10748.166422542694   \n",
       "1    zasięgnąć:ger opinia:subst 8210.697539476629   \n",
       "2    wykonywać:ger zawód:subst 4038.7485353954557   \n",
       "3  ograniczyć:ger wolność:subst 3909.855635819227   \n",
       "4      zawrzeć:ger umowa:subst 3661.9406491424647   \n",
       "\n",
       "                                prep adj  \\\n",
       "0     o:prep który:adj 98971.94897948248   \n",
       "1     w:prep który:adj 7387.952716919039   \n",
       "2  w:prep właściwy:adj 6000.002702112694   \n",
       "3     z:prep który:adj 4426.545214380086   \n",
       "4    do:prep który:adj 2693.229605673264   \n",
       "\n",
       "                                  prep brev  \n",
       "0      w:prep artykuł:brev 78823.4428443508  \n",
       "1      w:prep ustęp:brev 63539.375680707126  \n",
       "2       w:prep punkt:brev 7218.804944278644  \n",
       "3  z:prep późniejszy:brev 6559.177105338566  \n",
       "4   do:prep artykuł:brev 3601.7646793204017  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = {i:[] for i, _ in top10}\n",
    "\n",
    "for bigram,count in gram2_llr.items():\n",
    "    finished = True\n",
    "    for category in categories:\n",
    "        if len(categories[category]) <5:\n",
    "            finished = False\n",
    "            if inCategory(bigram,category):\n",
    "                categories[category].append(bigram+\" \"+str(count))\n",
    "    if finished:\n",
    "        break\n",
    "            \n",
    "df=pd.DataFrame.from_dict(categories,orient='index').transpose()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edea589",
   "metadata": {},
   "source": [
    "11. Using the results from the previous step answer the following questions:\n",
    "\n",
    "\n",
    "    i. What types of bigrams have been found? \n",
    "    \n",
    "The most common type of bigram type that was found are substantives (rzeczowniki). Nearly all most numerous categories consist of substantive plus something else \n",
    "\n",
    "    \n",
    "    ii. Which of the category-pairs indicate valuable multiword expressions? Do they have anything in common?\n",
    "    \n",
    "I think that the ones which don't have prepositions (prep) or coordinating conjunction (conj) are the ones that we are the most interested in. They often use substantive (rzeczownik) and adjective.\n",
    "    \n",
    "    iii. Which signal: LLR score or syntactic category is more useful for determining genuine multiword expressions?\n",
    "    \n",
    "LLR together with morphosyntactic category seems to be giving interesting results. It enables us to look at more precise categries eg. subst + adj or ger subst. There are some categories like those with conj that are less interesting for us, and using morphosyntactic category enables us to filter out those categories\n",
    "    \n",
    "    iv. Can you describe a different use-case where the morphosyntactic category is useful for resolving a real-world problem?\n",
    "    \n",
    "- finding words that tend to appear together eg. \"Rzeczpospolita Polska\" \n",
    "- chatbot - which speaks with a human by changing his words to questions and then asking those questions to maintain a conversation\n",
    "- translating text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
