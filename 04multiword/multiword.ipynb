{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiword expressions identification and extraction\n",
    "\n",
    "The task shows two simple methods useful for identifying multiword expressions (MWE) in corpora.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. Use SpaCy [tokenizer API](https://spacy.io/api/tokenizer) to tokenize the text from the law corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pl_PL.UTF-8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy download pl_core_news_sm\n",
    "import re\n",
    "import string\n",
    "import tarfile\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import morfeusz2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import spacy\n",
    "from elasticsearch import *\n",
    "from elasticsearch.helpers import *\n",
    "from elasticsearch_dsl import *\n",
    "from elasticsearch_dsl import query\n",
    "from spacy.tokenizer import *\n",
    "\n",
    "matplotlib.style.use(\"ggplot\")\n",
    "import math\n",
    "import operator\n",
    "import time\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "\n",
    "locale.setlocale(locale.LC_COLLATE, \"pl_PL.UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compute **bigram** counts of downcased tokens.  Given the sentence: \"The quick brown fox jumps over the\n",
    "   lazy dog.\", the bigram counts are as follows:\n",
    "   \n",
    "   * \"the quick\": 1\n",
    "   * \"quick brown\": 1\n",
    "   * \"brown fox\": 1\n",
    "   * . ...\n",
    "   * \"dog .\": 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "tokens = {}\n",
    "tokens_list = []\n",
    "i = 0\n",
    "path = \"../data/ustawy\"\n",
    "for filename in os.listdir(path):\n",
    "    with open(os.path.join(path, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "        act = file.read()\n",
    "        act = regex.sub(r\"\\s+\", \" \", act)\n",
    "        act = regex.sub(r\"­\", \"\", act)\n",
    "        act = act.lower()\n",
    "        words = [token.text for token in tokenizer(act)]\n",
    "        tokens[file.name] = words\n",
    "        tokens_list = tokens_list + words\n",
    "        i += 1\n",
    "        if i % 200 == 0:\n",
    "            print(i)\n",
    "\n",
    "old_tokens_list = tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', 'dz.u.', 'z', '1998', 'r.', 'nr', '117,', 'poz.', '759', 'ustawa']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(dictionary):\n",
    "    return dict(sorted(dictionary.items(), key=operator.itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new', ',', 'fast', ',', 'expensive']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separate_puctuations(tokens):\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        splitted = regex.findall(\n",
    "            r\"[\\w']+|[.,!?;]\", token\n",
    "        )  # https://stackoverflow.com/questions/367155/splitting-a-string-into-words-and-punctuation\n",
    "        new_tokens += splitted\n",
    "    return new_tokens\n",
    "\n",
    "\n",
    "tokens = [\"new,\", \"fast,\", \"expensive\"]\n",
    "separate_puctuations(tokens) #splitting into words and punctuation example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The quick', 'quick brown', 'brown fox', 'fox jumps', 'jumps over', 'over the', 'the lazy', 'lazy dog.']\n"
     ]
    }
   ],
   "source": [
    "def bigrams(words):\n",
    "    words = list(map(lambda x: x.strip(), words))\n",
    "    words = zip(words, words[1:])\n",
    "    return [\" \".join(pair) for pair in words]\n",
    "\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "words = [token.text for token in tokenizer(text)]\n",
    "print(bigrams(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = separate_puctuations(tokens_list)\n",
    "gram2 = bigrams(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('art .', 83779),\n",
       " ('ust .', 53552),\n",
       " ('poz .', 45222),\n",
       " ('. 1', 43484),\n",
       " (', poz', 43192)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(gram2).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "3. Discard bigrams containing characters other than letters. Make sure that you discard the invalid entries **after**\n",
    "   computing the bigram counts.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w art', 32045),\n",
       " ('mowa w', 28471),\n",
       " ('w ust', 23557),\n",
       " ('o których', 13885),\n",
       " ('których mowa', 13858)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = gram2.filter()\n",
    "gram2 = [\n",
    "    token\n",
    "    for token in gram2\n",
    "    if all(char not in string.punctuation and not char.isdigit() for char in token)\n",
    "]\n",
    "Counter(gram2).most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use [pointwise mutual information](https://en.wikipedia.org/wiki/Pointwise_mutual_information) to compute the measure \n",
    "   for all pairs of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_probabilities(tokens):\n",
    "    tokens_count = Counter(tokens)\n",
    "    count = sum(tokens_count.values())\n",
    "    return {k: v / count for k, v in tokens_count.items()}\n",
    "\n",
    "\n",
    "p_bigram = to_probabilities(gram2)\n",
    "\n",
    "\n",
    "p_token = to_probabilities(tokens_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi(x, y):  # pointwise_mutual_information\n",
    "    result = p_bigram[x + \" \" + y] / (p_token[x] * p_token[y])\n",
    "    return math.log2(result)\n",
    "\n",
    "\n",
    "gram2_pmi = {}\n",
    "for key in gram2:\n",
    "    if len(key.split()) > 2:\n",
    "        print(key)\n",
    "    gram2_pmi[key] = pmi(*key.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tery', 'torialnego']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separate_puctuations([\"tery­torialnego\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Sort the word pairs according to that measure in the descending order and determine top 10 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('korzy stający', 23.024484997199306),\n",
       " ('gałki ocznej', 23.024484997199306),\n",
       " ('przedemery talne', 23.024484997199306),\n",
       " ('organa uchwałodawcze', 23.024484997199306),\n",
       " ('kropki wstawić', 23.024484997199306),\n",
       " ('antykonkurencyjnym koncentracjom', 23.024484997199306),\n",
       " ('skupiających kibiców', 23.024484997199306),\n",
       " ('chuli gańskich', 23.024484997199306),\n",
       " ('znająca pjm', 23.024484997199306),\n",
       " ('przyspo sobieniu', 23.024484997199306)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram2_pmi = dict(sorted(gram2_pmi.items(), key=operator.itemgetter(1), reverse=True))\n",
    "list(gram2_pmi.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w',\n",
       " 'umowie',\n",
       " 'leasingu',\n",
       " 'zastrzeżono,',\n",
       " 'że',\n",
       " 'korzy',\n",
       " 'stający',\n",
       " 'będzie',\n",
       " 'ponosił',\n",
       " 'ciężar',\n",
       " 'tych',\n",
       " 'podatków',\n",
       " 'i',\n",
       " 'składek',\n",
       " 'niezależnie',\n",
       " 'od',\n",
       " 'opłat',\n",
       " 'za',\n",
       " 'używanie,',\n",
       " '3)',\n",
       " 'kaucji',\n",
       " 'określonej',\n",
       " 'w',\n",
       " 'umowie']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unfortunatelly some words are separated by new line and it was not possible to merge them together \"korzy\" \"stający\"\n",
    "\"\"\"             środków trwałych, jeżeli w umowie leasingu zastrzeżono, że korzy\n",
    "             stający będzie ponosił ciężar tych podatków i składek niezależnie\"\"\"\n",
    "old_tokens_list.index(\"korzy\")\n",
    "old_tokens_list[22536:22560]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Filter bigrams with number of occurrences lower than 5. Determine top 10 entries for the remaining dataset (>=5\n",
    "   occurrences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram2_count = Counter(gram2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('obiegów chłodzących', 20.70255690231194),\n",
       " ('otworami wiertniczymi', 20.70255690231194),\n",
       " ('świeckie przygotowujące', 20.70255690231194),\n",
       " ('zaszkodzić wynikom', 20.70255690231194),\n",
       " ('teryto rialnego', 20.70255690231194),\n",
       " ('klęskami żywiołowymi', 20.70255690231194),\n",
       " ('metalizacji natryskowej', 20.70255690231194),\n",
       " ('natryskiwania tworzywami', 20.70255690231194),\n",
       " ('past emulsyjnych', 20.70255690231194),\n",
       " ('młynki młotkowe', 20.70255690231194)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram2_pmi5 = {k: v for k, v in gram2_pmi.items() if gram2_count[k] >= 5}\n",
    "gram2_pmi5 = dict(sorted(gram2_pmi5.items(), key=operator.itemgetter(1), reverse=True))\n",
    "list(gram2_pmi5.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use [log likelihood ratio](http://tdunning.blogspot.com/2008/03/surprise-and-coincidence.html) (LLR) to compute the measure\n",
    "   for all pairs of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # How LLR algorithm should look like, but this implementation is too slow\n",
    "def H(k):\n",
    "    # print(k)\n",
    "    N = np.sum(k)\n",
    "    # print(N)\n",
    "    # print(np.sum(k/N * np.ma.log(k/N).filled(0)))\n",
    "    return np.sum(k/N * np.ma.log(k/N).filled(0))\n",
    "\n",
    "\n",
    "def llr(a,b):\n",
    "\n",
    "    k11 = gram2_count[a+' '+b]\n",
    "    k12 = sum([count for key, count in gram2_count.items() if not a in key and b in key])\n",
    "    k21 = sum([count for key, count in gram2_count.items() if a in key and not b in key])\n",
    "    k22 = sum([count for key, count in gram2_count.items() if not a in key and not b in key])\n",
    "    k = np.array([[k11,k12],[k21,k22]])\n",
    "    rowSums = np.sum(k, axis=1).tolist()\n",
    "    colSums = np.sum(k, axis=0).tolist()\n",
    "    \n",
    "    return 2* np.sum(k) * (H(k) - H(rowSums) - H(colSums))    \n",
    "\n",
    "\n",
    "llr('w','art2')\n",
    "\n",
    "bigram_llr =  {}\n",
    "length = len(gram2)\n",
    "i=0 \n",
    "for key in gram2:\n",
    "    if len(key.split())>2:\n",
    "        print(key)\n",
    "    bigram_llr[key] = llr(*key.split())\n",
    "    if i%10==0:\n",
    "        print(f'{i}/{length}')\n",
    "    print(key,bigram_llr[key])\n",
    "    i+=1\n",
    "    \n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "token_count = defaultdict(int)\n",
    "\n",
    "for bigram, count in gram2_count.items():\n",
    "    (first_token, second_token) = bigram.split()\n",
    "    token_count[first_token] += count\n",
    "    token_count[second_token] += count\n",
    "\n",
    "total = sum(gram2_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72556.59014900832"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def H(k):\n",
    "    N = np.sum(k)\n",
    "    return np.sum(k / N * np.ma.log(k / N).filled(0))\n",
    "\n",
    "\n",
    "def llr(a, b):\n",
    "\n",
    "    k11 = gram2_count[a + \" \" + b]\n",
    "    k12 = token_count[b] - k11\n",
    "    k21 = token_count[a] - k11\n",
    "    k22 = total - k21 - k12 - k11\n",
    "    k = np.array([[k11, k12], [k21, k22]])\n",
    "    rowSums = np.sum(k, axis=1).tolist()\n",
    "    colSums = np.sum(k, axis=0).tolist()\n",
    "\n",
    "    return 2 * np.sum(k) * (H(k) - H(rowSums) - H(colSums))\n",
    "\n",
    "\n",
    "llr(\"w\", \"art\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2837496\n",
      "283749/2837496\n",
      "567498/2837496\n",
      "851247/2837496\n",
      "1134996/2837496\n",
      "1418745/2837496\n",
      "1702494/2837496\n",
      "1986243/2837496\n",
      "2269992/2837496\n",
      "2553741/2837496\n",
      "2837490/2837496\n"
     ]
    }
   ],
   "source": [
    "gram2_llr = {}\n",
    "length = len(gram2)\n",
    "i = 0\n",
    "for key in gram2:\n",
    "    if len(key.split()) > 2:\n",
    "        print(key)\n",
    "    gram2_llr[key] = llr(*key.split())\n",
    "    if i % (int(length / 10)) == 0:\n",
    "        print(f\"{i}/{length}\")\n",
    "    # print(key,gram2_llr[key])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Sort the word pairs according to that measure in the descending order and display top 10 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('otrzymuje brzmienie', 102885.48395536352),\n",
       " ('w w', 88950.24561342891),\n",
       " ('w art', 72556.59014900832),\n",
       " ('których mowa', 65874.30552844425),\n",
       " ('w ust', 59140.47968532207),\n",
       " ('o których', 52416.33194280648),\n",
       " ('mowa w', 51071.7654550929),\n",
       " ('drodze rozporządzenia', 45996.84967469449),\n",
       " ('dodaje się', 43483.15738019904),\n",
       " ('którym mowa', 42425.906420601474)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram2_llr = dict(sorted(gram2_llr.items(), key=operator.itemgetter(1), reverse=True))\n",
    "list(gram2_llr.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gram2_llr5 = {k: v for k, v in Counter(gram2).items() if v >= 5}\n",
    "gram2_llr5 = dict(sorted(gram2_llr5.items(), key=operator.itemgetter(1), reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Compute **trigram** counts for the whole corpus and perform the same filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The quick brown', 'quick brown fox', 'brown fox jumps', 'fox jumps over', 'jumps over the', 'over the lazy', 'the lazy dog.']\n"
     ]
    }
   ],
   "source": [
    "def trigrams(words):\n",
    "    words = list(map(lambda x: x.strip(), words))\n",
    "    words = zip(words, words[1:], words[2:])\n",
    "    return [\" \".join(pair) for pair in words]\n",
    "\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "words = [token.text for token in tokenizer(text)]\n",
    "print(trigrams(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram3 = trigrams(tokens_list)\n",
    "gram3 = [\n",
    "    token\n",
    "    for token in gram3\n",
    "    if all(char not in string.punctuation and not char.isdigit() for char in token)\n",
    "]\n",
    "# gram3 = [ k for k, v in Counter(gram3).items() if v>=5] # filter with treshold = 5 (minimum 5 occurrences of the phrase)\n",
    "\n",
    "gram3_count = Counter(gram3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Use PMI (with 5 occurrence threshold) and LLR to compute top 10 results for the trigrams. Devise a method for computing the values, based on the\n",
    "   results for bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_probabilities(tokens):\n",
    "    tokens_count = Counter(tokens)\n",
    "    count = sum(tokens_count.values())\n",
    "    return {k: v / count for k, v in tokens_count.items()}\n",
    "\n",
    "\n",
    "p_gram3 = to_probabilities(gram3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi3(x, y, z):  # pointwise_mutual_information\n",
    "    result = p_gram3[x + \" \" + y + \" \" + z] / (p_token[x] * p_token[y] * p_token[z])\n",
    "    return math.log2(result)\n",
    "\n",
    "\n",
    "gram3_pmi = {}\n",
    "for key in gram3:\n",
    "    if len(key.split()) != 3:\n",
    "        print(key)\n",
    "    gram3_pmi[key] = pmi3(*key.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pozyskać sortymentów drzewnych', 45.52475039226819),\n",
       " ('restytucji world jewish', 45.52475039226819),\n",
       " ('world jewish restitution', 45.52475039226819),\n",
       " ('jewish restitution organisation', 45.52475039226819),\n",
       " ('prosimy uważnie przeczytać', 45.52475039226819),\n",
       " ('uważnie przeczytać poniższą', 45.52475039226819),\n",
       " ('szyciem naciętego krocza', 45.52475039226819),\n",
       " ('ostrzeżony strzałami ostrzegawczymi', 45.52475039226819),\n",
       " ('ekstrakt ketobemidon cliradon', 45.52475039226819),\n",
       " ('karboksymetylo oksym dihydrokodeinonu', 45.52475039226819)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram3_pmi = sort_dict(gram3_pmi)\n",
    "list(gram3_pmi.items())[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram3_count = Counter(gram3)\n",
    "gram3_pmi5 = {k: v for k, v in gram3_pmi.items() if gram3_count[k] >= 5}\n",
    "gram3_pmi5 = dict(sorted(gram3_pmi5.items(), key=operator.itemgetter(1), reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "Regarding trigrams, one of the easiest implementations is to simply make a pass looking for significant bigrams. Then, considering those bigrams as single words, make another pass looking for bigrams that include bigrams from the first pass. These composite bigrams are really trigrams. You can repeat this process as you like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "token_count = defaultdict(int)\n",
    "\n",
    "\n",
    "for trigram, count in gram3_count.items():\n",
    "    (a, b, c) = trigram.split()\n",
    "    first_token = a + \" \" + b\n",
    "    second_token = b + \" \" + c\n",
    "    token_count[first_token] += count\n",
    "    token_count[second_token] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2353306\n"
     ]
    }
   ],
   "source": [
    "total = len(gram3)\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(k):\n",
    "    # print(k)\n",
    "\n",
    "    N = np.sum(k)\n",
    "    # print(N)\n",
    "    # print(np.sum(k/N * np.ma.log(k/N).filled(0)))\n",
    "    return np.sum(k / N * np.ma.log(k / N).filled(0))\n",
    "\n",
    "\n",
    "def llr3(a, b, trigram):\n",
    "\n",
    "    k11 = gram3_count[trigram]\n",
    "    k12 = token_count[b] - k11\n",
    "    k21 = token_count[a] - k11\n",
    "    k22 = total - k21 - k12 - k11\n",
    "    k = np.array([[k11, k12], [k21, k22]])\n",
    "    rowSums = np.sum(k, axis=1).tolist()\n",
    "    colSums = np.sum(k, axis=0).tolist()\n",
    "\n",
    "    return 2 * np.sum(k) * (H(k) - H(rowSums) - H(colSums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2353306\n",
      "235330/2353306\n",
      "470660/2353306\n",
      "705990/2353306\n",
      "941320/2353306\n",
      "1176650/2353306\n",
      "1411980/2353306\n",
      "1647310/2353306\n",
      "1882640/2353306\n",
      "2117970/2353306\n",
      "2353300/2353306\n"
     ]
    }
   ],
   "source": [
    "gram3_llr = {}\n",
    "length = len(gram3)\n",
    "i = 0\n",
    "for key in gram3:\n",
    "    if len(key.split()) != 3:\n",
    "        print(key)\n",
    "    (word1, word2, word3) = key.split()\n",
    "\n",
    "    first_token = f\"{word1} {word2}\"\n",
    "    second_token = f\"{word2} {word3}\"\n",
    "\n",
    "    gram3_llr[key] = llr3(first_token, second_token, key)\n",
    "\n",
    "    if i % (int(length / 10)) == 0:\n",
    "        print(f\"{i}/{length}\")\n",
    "    # print(key,gram2_llr[key])\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram3_llr =(dict(sorted(gram3_llr.items(), key=lambda item: item[1],reverse=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram3_llr5 = {k: v for k, v in Counter(gram3).items() if v >= 5}\n",
    "gram3_llr5 = dict(sorted(gram3_llr5.items(), key=operator.itemgetter(1), reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Create a table comparing the methods (separate table for bigrams and trigrams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ustawa z', 5.24992414625927),\n",
       " ('z dnia', 5.778516878792047),\n",
       " ('o zmianie', 6.81580808417473),\n",
       " ('zmianie ustawy', 8.510678895092788),\n",
       " ('ustawy o', 3.8602631638142415),\n",
       " ('o systemie', 5.968833836638906),\n",
       " ('systemie oświaty', 10.989844384358635),\n",
       " ('oświaty art', -0.29315970870050306),\n",
       " ('w ustawie', 5.324952584311153),\n",
       " ('ustawie z', 6.114202585886397)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gram2_pmi.items())[0:10]\n",
    "# table_trigrams_llr = copy.deepcopy(sorted(gram3_llr.items(), key=lambda x: -x[1]))\n",
    "# table_trigrams_pmi = copy.deepcopy(sorted(gram3_pmi.items(), key=lambda x: -x[1]))\n",
    "# table_bigrams_llr = copy.deepcopy(sorted(gram2_llr.items(), key=lambda x: -x[1]))\n",
    "# table_bigrams_pmi = copy.deepcopy(sorted(gram2_pmi.items(), key=lambda x: -x[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram2_pmi</th>\n",
       "      <th>gram2_pmi5</th>\n",
       "      <th>gram2_llr</th>\n",
       "      <th>gram2_llr5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(korzy stający, 23.024484997199306)</td>\n",
       "      <td>(obiegów chłodzących, 20.70255690231194)</td>\n",
       "      <td>(otrzymuje brzmienie, 102885.48395536352)</td>\n",
       "      <td>(otrzymuje brzmienie, 102885.48395536352)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(gałki ocznej, 23.024484997199306)</td>\n",
       "      <td>(otworami wiertniczymi, 20.70255690231194)</td>\n",
       "      <td>(w w, 88950.24561342891)</td>\n",
       "      <td>(w w, 88950.24561342891)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(przedemery talne, 23.024484997199306)</td>\n",
       "      <td>(świeckie przygotowujące, 20.70255690231194)</td>\n",
       "      <td>(w art, 72556.59014900832)</td>\n",
       "      <td>(w art, 72556.59014900832)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(organa uchwałodawcze, 23.024484997199306)</td>\n",
       "      <td>(zaszkodzić wynikom, 20.70255690231194)</td>\n",
       "      <td>(których mowa, 65874.30552844425)</td>\n",
       "      <td>(których mowa, 65874.30552844425)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(kropki wstawić, 23.024484997199306)</td>\n",
       "      <td>(teryto rialnego, 20.70255690231194)</td>\n",
       "      <td>(w ust, 59140.47968532207)</td>\n",
       "      <td>(w ust, 59140.47968532207)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(antykonkurencyjnym koncentracjom, 23.02448499...</td>\n",
       "      <td>(klęskami żywiołowymi, 20.70255690231194)</td>\n",
       "      <td>(o których, 52416.33194280648)</td>\n",
       "      <td>(o których, 52416.33194280648)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(skupiających kibiców, 23.024484997199306)</td>\n",
       "      <td>(metalizacji natryskowej, 20.70255690231194)</td>\n",
       "      <td>(mowa w, 51071.7654550929)</td>\n",
       "      <td>(mowa w, 51071.7654550929)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(chuli gańskich, 23.024484997199306)</td>\n",
       "      <td>(natryskiwania tworzywami, 20.70255690231194)</td>\n",
       "      <td>(drodze rozporządzenia, 45996.84967469449)</td>\n",
       "      <td>(drodze rozporządzenia, 45996.84967469449)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(znająca pjm, 23.024484997199306)</td>\n",
       "      <td>(past emulsyjnych, 20.70255690231194)</td>\n",
       "      <td>(dodaje się, 43483.15738019904)</td>\n",
       "      <td>(dodaje się, 43483.15738019904)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(przyspo sobieniu, 23.024484997199306)</td>\n",
       "      <td>(młynki młotkowe, 20.70255690231194)</td>\n",
       "      <td>(którym mowa, 42425.906420601474)</td>\n",
       "      <td>(którym mowa, 42425.906420601474)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(skoczów komorowice, 23.024484997199306)</td>\n",
       "      <td>(ekrany kinowe, 20.70255690231194)</td>\n",
       "      <td>(i nr, 41886.19348378814)</td>\n",
       "      <td>(i nr, 41886.19348378814)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(mówił szczerą, 23.024484997199306)</td>\n",
       "      <td>(młyny kulowe, 20.70255690231194)</td>\n",
       "      <td>(minister właściwy, 39539.04214363478)</td>\n",
       "      <td>(minister właściwy, 39539.04214363478)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(uczucie wstydu, 23.024484997199306)</td>\n",
       "      <td>(najnowszych zdobyczy, 20.70255690231194)</td>\n",
       "      <td>(w i, 36793.85822369282)</td>\n",
       "      <td>(w i, 36793.85822369282)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(nuklidy rozszczepialne, 23.024484997199306)</td>\n",
       "      <td>(grzegorz schetyna, 20.70255690231194)</td>\n",
       "      <td>(o którym, 33843.66988989214)</td>\n",
       "      <td>(o którym, 33843.66988989214)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(nm nanometrów, 23.024484997199306)</td>\n",
       "      <td>(ręcznego miotacza, 20.70255690231194)</td>\n",
       "      <td>(rzeczypospolitej polskiej, 33569.22897909207)</td>\n",
       "      <td>(rzeczypospolitej polskiej, 33569.22897909207)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(aparatami rentgenowskimi, 23.024484997199306)</td>\n",
       "      <td>(środa wlkp, 20.70255690231194)</td>\n",
       "      <td>(stosuje się, 32448.263758649955)</td>\n",
       "      <td>(stosuje się, 32448.263758649955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(stabilnym jodem, 23.024484997199306)</td>\n",
       "      <td>(obcowania płciowego, 20.70255690231194)</td>\n",
       "      <td>(z dnia, 30621.884528580806)</td>\n",
       "      <td>(z dnia, 30621.884528580806)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(stemplach kontrolerskich, 23.024484997199306)</td>\n",
       "      <td>(nietykalność cielesną, 20.70255690231194)</td>\n",
       "      <td>(do spraw, 30501.65240743863)</td>\n",
       "      <td>(do spraw, 30501.65240743863)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(uczynieniu nieczytelnym, 23.024484997199306)</td>\n",
       "      <td>(dosiadanie powożenie, 20.70255690231194)</td>\n",
       "      <td>(z w, 30177.393943712257)</td>\n",
       "      <td>(z w, 30177.393943712257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(odvjetnik odvjetnica, 23.024484997199306)</td>\n",
       "      <td>(stajnią wyścigową, 20.70255690231194)</td>\n",
       "      <td>(w z, 30037.615909239837)</td>\n",
       "      <td>(w z, 30037.615909239837)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            gram2_pmi  \\\n",
       "0                 (korzy stający, 23.024484997199306)   \n",
       "1                  (gałki ocznej, 23.024484997199306)   \n",
       "2              (przedemery talne, 23.024484997199306)   \n",
       "3          (organa uchwałodawcze, 23.024484997199306)   \n",
       "4                (kropki wstawić, 23.024484997199306)   \n",
       "5   (antykonkurencyjnym koncentracjom, 23.02448499...   \n",
       "6          (skupiających kibiców, 23.024484997199306)   \n",
       "7                (chuli gańskich, 23.024484997199306)   \n",
       "8                   (znająca pjm, 23.024484997199306)   \n",
       "9              (przyspo sobieniu, 23.024484997199306)   \n",
       "10           (skoczów komorowice, 23.024484997199306)   \n",
       "11                (mówił szczerą, 23.024484997199306)   \n",
       "12               (uczucie wstydu, 23.024484997199306)   \n",
       "13       (nuklidy rozszczepialne, 23.024484997199306)   \n",
       "14                (nm nanometrów, 23.024484997199306)   \n",
       "15     (aparatami rentgenowskimi, 23.024484997199306)   \n",
       "16              (stabilnym jodem, 23.024484997199306)   \n",
       "17     (stemplach kontrolerskich, 23.024484997199306)   \n",
       "18      (uczynieniu nieczytelnym, 23.024484997199306)   \n",
       "19         (odvjetnik odvjetnica, 23.024484997199306)   \n",
       "\n",
       "                                       gram2_pmi5  \\\n",
       "0        (obiegów chłodzących, 20.70255690231194)   \n",
       "1      (otworami wiertniczymi, 20.70255690231194)   \n",
       "2    (świeckie przygotowujące, 20.70255690231194)   \n",
       "3         (zaszkodzić wynikom, 20.70255690231194)   \n",
       "4            (teryto rialnego, 20.70255690231194)   \n",
       "5       (klęskami żywiołowymi, 20.70255690231194)   \n",
       "6    (metalizacji natryskowej, 20.70255690231194)   \n",
       "7   (natryskiwania tworzywami, 20.70255690231194)   \n",
       "8           (past emulsyjnych, 20.70255690231194)   \n",
       "9            (młynki młotkowe, 20.70255690231194)   \n",
       "10             (ekrany kinowe, 20.70255690231194)   \n",
       "11              (młyny kulowe, 20.70255690231194)   \n",
       "12      (najnowszych zdobyczy, 20.70255690231194)   \n",
       "13         (grzegorz schetyna, 20.70255690231194)   \n",
       "14         (ręcznego miotacza, 20.70255690231194)   \n",
       "15                (środa wlkp, 20.70255690231194)   \n",
       "16       (obcowania płciowego, 20.70255690231194)   \n",
       "17     (nietykalność cielesną, 20.70255690231194)   \n",
       "18      (dosiadanie powożenie, 20.70255690231194)   \n",
       "19         (stajnią wyścigową, 20.70255690231194)   \n",
       "\n",
       "                                         gram2_llr  \\\n",
       "0        (otrzymuje brzmienie, 102885.48395536352)   \n",
       "1                         (w w, 88950.24561342891)   \n",
       "2                       (w art, 72556.59014900832)   \n",
       "3                (których mowa, 65874.30552844425)   \n",
       "4                       (w ust, 59140.47968532207)   \n",
       "5                   (o których, 52416.33194280648)   \n",
       "6                       (mowa w, 51071.7654550929)   \n",
       "7       (drodze rozporządzenia, 45996.84967469449)   \n",
       "8                  (dodaje się, 43483.15738019904)   \n",
       "9                (którym mowa, 42425.906420601474)   \n",
       "10                       (i nr, 41886.19348378814)   \n",
       "11          (minister właściwy, 39539.04214363478)   \n",
       "12                        (w i, 36793.85822369282)   \n",
       "13                   (o którym, 33843.66988989214)   \n",
       "14  (rzeczypospolitej polskiej, 33569.22897909207)   \n",
       "15               (stosuje się, 32448.263758649955)   \n",
       "16                    (z dnia, 30621.884528580806)   \n",
       "17                   (do spraw, 30501.65240743863)   \n",
       "18                       (z w, 30177.393943712257)   \n",
       "19                       (w z, 30037.615909239837)   \n",
       "\n",
       "                                        gram2_llr5  \n",
       "0        (otrzymuje brzmienie, 102885.48395536352)  \n",
       "1                         (w w, 88950.24561342891)  \n",
       "2                       (w art, 72556.59014900832)  \n",
       "3                (których mowa, 65874.30552844425)  \n",
       "4                       (w ust, 59140.47968532207)  \n",
       "5                   (o których, 52416.33194280648)  \n",
       "6                       (mowa w, 51071.7654550929)  \n",
       "7       (drodze rozporządzenia, 45996.84967469449)  \n",
       "8                  (dodaje się, 43483.15738019904)  \n",
       "9                (którym mowa, 42425.906420601474)  \n",
       "10                       (i nr, 41886.19348378814)  \n",
       "11          (minister właściwy, 39539.04214363478)  \n",
       "12                        (w i, 36793.85822369282)  \n",
       "13                   (o którym, 33843.66988989214)  \n",
       "14  (rzeczypospolitej polskiej, 33569.22897909207)  \n",
       "15               (stosuje się, 32448.263758649955)  \n",
       "16                    (z dnia, 30621.884528580806)  \n",
       "17                   (do spraw, 30501.65240743863)  \n",
       "18                       (z w, 30177.393943712257)  \n",
       "19                       (w z, 30037.615909239837)  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "\t'gram2_pmi' : list(gram2_pmi.items())[0:20],\n",
    "    'gram2_pmi5' : list(gram2_pmi5.items())[0:20],\n",
    "    'gram2_llr' : list(gram2_llr.items())[0:20],\n",
    "    'gram2_llr5' : list(gram2_llr.items())[0:20]\n",
    "    \n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram3_pmi</th>\n",
       "      <th>gram3_pmi5</th>\n",
       "      <th>gram3_llr</th>\n",
       "      <th>gram3_llr5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(pozyskać sortymentów drzewnych, 45.5247503922...</td>\n",
       "      <td>(topienia żużla wielkopiecowego, 40.3548253908...</td>\n",
       "      <td>(o których mowa, 130326.30749652752)</td>\n",
       "      <td>(o których mowa, 13857)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(restytucji world jewish, 45.52475039226819)</td>\n",
       "      <td>(porcelanowe młyny kulowe, 39.880894202493465)</td>\n",
       "      <td>(o którym mowa, 93966.98951460843)</td>\n",
       "      <td>(których mowa w, 13807)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(world jewish restitution, 45.52475039226819)</td>\n",
       "      <td>(wymienniki przeponowe rurowe, 39.48035627290974)</td>\n",
       "      <td>(mowa w ust, 80683.70742976072)</td>\n",
       "      <td>(mowa w ust, 13474)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(jewish restitution organisation, 45.524750392...</td>\n",
       "      <td>(akumulatora ołowiowego kwasowego, 39.13243296...</td>\n",
       "      <td>(mowa w art, 70985.86883561742)</td>\n",
       "      <td>(mowa w art, 12311)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(prosimy uważnie przeczytać, 45.52475039226819)</td>\n",
       "      <td>(partnerstwie publiczno prywatnym, 39.03932356...</td>\n",
       "      <td>(których mowa w, 69167.67451145055)</td>\n",
       "      <td>(o którym mowa, 9169)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(uważnie przeczytać poniższą, 45.52475039226819)</td>\n",
       "      <td>(rozdziałach xxxix xliv, 38.91004054815298)</td>\n",
       "      <td>(o której mowa, 61914.80145216781)</td>\n",
       "      <td>(którym mowa w, 9147)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(szyciem naciętego krocza, 45.52475039226819)</td>\n",
       "      <td>(marii curie skłodowskiej, 38.880894202493465)</td>\n",
       "      <td>(w drodze rozporządzenia, 55068.65940835584)</td>\n",
       "      <td>(o której mowa, 5511)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(ostrzeżony strzałami ostrzegawczymi, 45.52475...</td>\n",
       "      <td>(finałowego turnieju mistrzostw, 38.3648790554...</td>\n",
       "      <td>(minister właściwy do, 47977.772785700996)</td>\n",
       "      <td>(której mowa w, 5488)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(ekstrakt ketobemidon cliradon, 45.52475039226...</td>\n",
       "      <td>(profilem zaufanym epuap, 38.12387095598601)</td>\n",
       "      <td>(którym mowa w, 45011.20512861168)</td>\n",
       "      <td>(w drodze rozporządzenia, 4691)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(karboksymetylo oksym dihydrokodeinonu, 45.524...</td>\n",
       "      <td>(cienką sierścią zwierzęcą, 38.06531877363089)</td>\n",
       "      <td>(w ustawie z, 35392.380207012866)</td>\n",
       "      <td>(właściwy do spraw, 4620)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(nitro benzimidazol leonotis, 45.52475039226819)</td>\n",
       "      <td>(akumulatory ołowiowe kwasowe, 38.02225005173901)</td>\n",
       "      <td>(otrzymuje brzmienie art, 34640.72003021394)</td>\n",
       "      <td>(minister właściwy do, 4601)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(benzimidazol leonotis leonurus, 45.5247503922...</td>\n",
       "      <td>(przedwczesnego wyrębu drzewostanu, 37.9397878...</td>\n",
       "      <td>(właściwy do spraw, 33387.771483156255)</td>\n",
       "      <td>(ustawie z dnia, 3649)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(deoksymorfina metylodihydromor fina, 45.52475...</td>\n",
       "      <td>(natryskiwania tworzywami sztucznymi, 37.88089...</td>\n",
       "      <td>(ustawie z dnia, 31925.559946377118)</td>\n",
       "      <td>(w ustawie z, 3645)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(hostilis mitragyna speciosa, 45.52475039226819)</td>\n",
       "      <td>(centralnemu biuru antykorupcyjnemu, 37.673001...</td>\n",
       "      <td>(ustawy z dnia, 29301.265829840195)</td>\n",
       "      <td>(stosuje się odpowiednio, 3091)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(diolu mppp propionian, 45.52475039226819)</td>\n",
       "      <td>(turnieju mistrzostw europy, 37.59934430912682)</td>\n",
       "      <td>(stosuje się odpowiednio, 28435.049127597198)</td>\n",
       "      <td>(ustawy z dnia, 3055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(propylotiofenetyloamina brolamfetamina dob, 4...</td>\n",
       "      <td>(potwierdzonym profilem zaufanym, 37.576383160...</td>\n",
       "      <td>(dodaje się ust, 26994.470180511646)</td>\n",
       "      <td>(zastępuje się wyrazami, 2940)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(metylotioamfetamina etycyklidyna pce, 45.5247...</td>\n",
       "      <td>(szybkiemu postępowi technicznemu, 37.44793479...</td>\n",
       "      <td>(której mowa w, 26613.345556062668)</td>\n",
       "      <td>(dodaje się ust, 2766)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(indolilu rolicyklidyna php, 45.52475039226819)</td>\n",
       "      <td>(wiatrem wind cheater, 37.437287551017846)</td>\n",
       "      <td>(zastępuje się wyrazami, 26201.47517346995)</td>\n",
       "      <td>(otrzymuje brzmienie art, 2643)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(stylizowanymi liśćmi wawrzynu, 45.52475039226...</td>\n",
       "      <td>(wiatrem wind jacket, 37.437287551017846)</td>\n",
       "      <td>(się następujące zmiany, 24112.679531671434)</td>\n",
       "      <td>(wejścia w życie, 2354)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(eur szylingów austriackich, 45.52475039226819)</td>\n",
       "      <td>(piłce nożnej uefa, 37.42882597226966)</td>\n",
       "      <td>(wprowadza się następujące, 23727.611179452793)</td>\n",
       "      <td>(dni od dnia, 2074)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            gram3_pmi  \\\n",
       "0   (pozyskać sortymentów drzewnych, 45.5247503922...   \n",
       "1        (restytucji world jewish, 45.52475039226819)   \n",
       "2       (world jewish restitution, 45.52475039226819)   \n",
       "3   (jewish restitution organisation, 45.524750392...   \n",
       "4     (prosimy uważnie przeczytać, 45.52475039226819)   \n",
       "5    (uważnie przeczytać poniższą, 45.52475039226819)   \n",
       "6       (szyciem naciętego krocza, 45.52475039226819)   \n",
       "7   (ostrzeżony strzałami ostrzegawczymi, 45.52475...   \n",
       "8   (ekstrakt ketobemidon cliradon, 45.52475039226...   \n",
       "9   (karboksymetylo oksym dihydrokodeinonu, 45.524...   \n",
       "10   (nitro benzimidazol leonotis, 45.52475039226819)   \n",
       "11  (benzimidazol leonotis leonurus, 45.5247503922...   \n",
       "12  (deoksymorfina metylodihydromor fina, 45.52475...   \n",
       "13   (hostilis mitragyna speciosa, 45.52475039226819)   \n",
       "14         (diolu mppp propionian, 45.52475039226819)   \n",
       "15  (propylotiofenetyloamina brolamfetamina dob, 4...   \n",
       "16  (metylotioamfetamina etycyklidyna pce, 45.5247...   \n",
       "17    (indolilu rolicyklidyna php, 45.52475039226819)   \n",
       "18  (stylizowanymi liśćmi wawrzynu, 45.52475039226...   \n",
       "19    (eur szylingów austriackich, 45.52475039226819)   \n",
       "\n",
       "                                           gram3_pmi5  \\\n",
       "0   (topienia żużla wielkopiecowego, 40.3548253908...   \n",
       "1      (porcelanowe młyny kulowe, 39.880894202493465)   \n",
       "2   (wymienniki przeponowe rurowe, 39.48035627290974)   \n",
       "3   (akumulatora ołowiowego kwasowego, 39.13243296...   \n",
       "4   (partnerstwie publiczno prywatnym, 39.03932356...   \n",
       "5         (rozdziałach xxxix xliv, 38.91004054815298)   \n",
       "6      (marii curie skłodowskiej, 38.880894202493465)   \n",
       "7   (finałowego turnieju mistrzostw, 38.3648790554...   \n",
       "8        (profilem zaufanym epuap, 38.12387095598601)   \n",
       "9      (cienką sierścią zwierzęcą, 38.06531877363089)   \n",
       "10  (akumulatory ołowiowe kwasowe, 38.02225005173901)   \n",
       "11  (przedwczesnego wyrębu drzewostanu, 37.9397878...   \n",
       "12  (natryskiwania tworzywami sztucznymi, 37.88089...   \n",
       "13  (centralnemu biuru antykorupcyjnemu, 37.673001...   \n",
       "14    (turnieju mistrzostw europy, 37.59934430912682)   \n",
       "15  (potwierdzonym profilem zaufanym, 37.576383160...   \n",
       "16  (szybkiemu postępowi technicznemu, 37.44793479...   \n",
       "17         (wiatrem wind cheater, 37.437287551017846)   \n",
       "18          (wiatrem wind jacket, 37.437287551017846)   \n",
       "19             (piłce nożnej uefa, 37.42882597226966)   \n",
       "\n",
       "                                          gram3_llr  \\\n",
       "0              (o których mowa, 130326.30749652752)   \n",
       "1                (o którym mowa, 93966.98951460843)   \n",
       "2                   (mowa w ust, 80683.70742976072)   \n",
       "3                   (mowa w art, 70985.86883561742)   \n",
       "4               (których mowa w, 69167.67451145055)   \n",
       "5                (o której mowa, 61914.80145216781)   \n",
       "6      (w drodze rozporządzenia, 55068.65940835584)   \n",
       "7        (minister właściwy do, 47977.772785700996)   \n",
       "8                (którym mowa w, 45011.20512861168)   \n",
       "9                 (w ustawie z, 35392.380207012866)   \n",
       "10     (otrzymuje brzmienie art, 34640.72003021394)   \n",
       "11          (właściwy do spraw, 33387.771483156255)   \n",
       "12             (ustawie z dnia, 31925.559946377118)   \n",
       "13              (ustawy z dnia, 29301.265829840195)   \n",
       "14    (stosuje się odpowiednio, 28435.049127597198)   \n",
       "15             (dodaje się ust, 26994.470180511646)   \n",
       "16              (której mowa w, 26613.345556062668)   \n",
       "17      (zastępuje się wyrazami, 26201.47517346995)   \n",
       "18     (się następujące zmiany, 24112.679531671434)   \n",
       "19  (wprowadza się następujące, 23727.611179452793)   \n",
       "\n",
       "                         gram3_llr5  \n",
       "0           (o których mowa, 13857)  \n",
       "1           (których mowa w, 13807)  \n",
       "2               (mowa w ust, 13474)  \n",
       "3               (mowa w art, 12311)  \n",
       "4             (o którym mowa, 9169)  \n",
       "5             (którym mowa w, 9147)  \n",
       "6             (o której mowa, 5511)  \n",
       "7             (której mowa w, 5488)  \n",
       "8   (w drodze rozporządzenia, 4691)  \n",
       "9         (właściwy do spraw, 4620)  \n",
       "10     (minister właściwy do, 4601)  \n",
       "11           (ustawie z dnia, 3649)  \n",
       "12              (w ustawie z, 3645)  \n",
       "13  (stosuje się odpowiednio, 3091)  \n",
       "14            (ustawy z dnia, 3055)  \n",
       "15   (zastępuje się wyrazami, 2940)  \n",
       "16           (dodaje się ust, 2766)  \n",
       "17  (otrzymuje brzmienie art, 2643)  \n",
       "18          (wejścia w życie, 2354)  \n",
       "19              (dni od dnia, 2074)  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "\t'gram3_pmi' : list(gram3_pmi.items())[0:20],\n",
    "    'gram3_pmi5' : list(gram3_pmi5.items())[0:20],\n",
    "    'gram3_llr' : list(gram3_llr.items())[0:20],\n",
    "    'gram3_llr5' : list(gram3_llr5.items())[0:20]\n",
    "    \n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gram3_llr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_trigrams5_llr = copy.deepcopy(sorted(gram3_llr.items(), key=lambda x: -x[1]))\n",
    "# table_trigrams5_pmi = copy.deepcopy(sorted(gram3_pmi.items(), key=lambda x: -x[1]))\n",
    "# table_bigrams5_llr = copy.deepcopy(sorted(gram2_llr.items(), key=lambda x: -x[1]))\n",
    "# table_bigrams5_pmi = copy.deepcopy(sorted(gram2_pmi.items(), key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Answer the following questions:\n",
    "\n",
    "   a. Why do we have to filter the bigrams, rather than the token sequence?\n",
    "   \n",
    "   Because otherwise eg where is the end of the sentence we would get bigrams from the last word in the sentence and the first in the next sentence.\n",
    "   Simiraly for commas.\n",
    "   \n",
    "   b. Which measure (PMI, PMI with filtering, LLR) works better for the bigrams and which for the trigrams?\n",
    "   \n",
    "   \n",
    "   \n",
    "   c. What types of expressions are discovered by the methods.\n",
    "   \n",
    "   d. Can you devise a different type of filtering that would yield better results?\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
