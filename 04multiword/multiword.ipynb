{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiword expressions identification and extraction\n",
    "\n",
    "The task shows two simple methods useful for identifying multiword expressions (MWE) in corpora.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. Use SpaCy [tokenizer API](https://spacy.io/api/tokenizer) to tokenize the text from the law corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pl_PL.UTF-8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy download pl_core_news_sm\n",
    "import re\n",
    "import string\n",
    "import tarfile\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import morfeusz2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "import spacy\n",
    "from elasticsearch import *\n",
    "from elasticsearch.helpers import *\n",
    "from elasticsearch_dsl import *\n",
    "from elasticsearch_dsl import query\n",
    "from spacy.tokenizer import *\n",
    "\n",
    "matplotlib.style.use(\"ggplot\")\n",
    "import math\n",
    "import operator\n",
    "import time\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "\n",
    "locale.setlocale(locale.LC_COLLATE, \"pl_PL.UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compute **bigram** counts of downcased tokens.  Given the sentence: \"The quick brown fox jumps over the\n",
    "   lazy dog.\", the bigram counts are as follows:\n",
    "   \n",
    "   * \"the quick\": 1\n",
    "   * \"quick brown\": 1\n",
    "   * \"brown fox\": 1\n",
    "   * . ...\n",
    "   * \"dog .\": 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "tokens = {}\n",
    "tokens_list = []\n",
    "i = 0\n",
    "path = \"../data/ustawy\"\n",
    "for filename in os.listdir(path):\n",
    "    with open(os.path.join(path, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "        act = file.read()\n",
    "        act = regex.sub(r\"\\s+\", \" \", act)\n",
    "        act = regex.sub(r\"­\", \"\", act)\n",
    "        act = act.lower()\n",
    "        words = [token.text for token in tokenizer(act)]\n",
    "        tokens[file.name] = words\n",
    "        tokens_list = tokens_list + words\n",
    "        i += 1\n",
    "        if i % 200 == 0:\n",
    "            print(i)\n",
    "\n",
    "old_tokens_list = tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', 'dz.u.', 'z', '1998', 'r.', 'nr', '117,', 'poz.', '759', 'ustawa']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new', ',', 'fast', ',', 'expensive']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separate_puctuations(tokens):\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        splitted = regex.findall(\n",
    "            r\"[\\w']+|[.,!?;]\", token\n",
    "        )  # https://stackoverflow.com/questions/367155/splitting-a-string-into-words-and-punctuation\n",
    "        new_tokens += splitted\n",
    "    return new_tokens\n",
    "\n",
    "\n",
    "tokens = [\"new,\", \"fast,\", \"expensive\"]\n",
    "separate_puctuations(tokens) #splitting into words and punctuation example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The quick', 'quick brown', 'brown fox', 'fox jumps', 'jumps over', 'over the', 'the lazy', 'lazy dog.']\n"
     ]
    }
   ],
   "source": [
    "def bigrams(words):\n",
    "    words = list(map(lambda x: x.strip(), words))\n",
    "    words = zip(words, words[1:])\n",
    "    return [\" \".join(pair) for pair in words]\n",
    "\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "words = [token.text for token in tokenizer(text)]\n",
    "print(bigrams(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = separate_puctuations(tokens_list)\n",
    "gram2 = bigrams(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('art .', 83779),\n",
       " ('ust .', 53552),\n",
       " ('poz .', 45222),\n",
       " ('. 1', 43484),\n",
       " (', poz', 43192)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(gram2).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "3. Discard bigrams containing characters other than letters. Make sure that you discard the invalid entries **after**\n",
    "   computing the bigram counts.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w art', 32045),\n",
       " ('mowa w', 28471),\n",
       " ('w ust', 23557),\n",
       " ('o których', 13885),\n",
       " ('których mowa', 13858)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = gram2.filter()\n",
    "gram2 = [\n",
    "    token\n",
    "    for token in gram2\n",
    "    if all(char not in string.punctuation and not char.isdigit() for char in token)\n",
    "]\n",
    "Counter(gram2).most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use [pointwise mutual information](https://en.wikipedia.org/wiki/Pointwise_mutual_information) to compute the measure \n",
    "   for all pairs of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_probabilities(tokens):\n",
    "    tokens_count = Counter(tokens)\n",
    "    count = sum(tokens_count.values())\n",
    "    return {k: v / count for k, v in tokens_count.items()}\n",
    "\n",
    "\n",
    "p_bigram = to_probabilities(gram2)\n",
    "\n",
    "\n",
    "p_token = to_probabilities(tokens_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi(x, y):  # pointwise_mutual_information\n",
    "    result = p_bigram[x + \" \" + y] / (p_token[x] * p_token[y])\n",
    "    return math.log2(result)\n",
    "\n",
    "\n",
    "gram2_pmi = {}\n",
    "for key in gram2:\n",
    "    if len(key.split()) > 2:\n",
    "        print(key)\n",
    "    gram2_pmi[key] = pmi(*key.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('korzy stający', 23.024484997199306),\n",
       " ('gałki ocznej', 23.024484997199306),\n",
       " ('przedemery talne', 23.024484997199306),\n",
       " ('organa uchwałodawcze', 23.024484997199306),\n",
       " ('kropki wstawić', 23.024484997199306),\n",
       " ('antykonkurencyjnym koncentracjom', 23.024484997199306),\n",
       " ('skupiających kibiców', 23.024484997199306),\n",
       " ('chuli gańskich', 23.024484997199306),\n",
       " ('znająca pjm', 23.024484997199306),\n",
       " ('przyspo sobieniu', 23.024484997199306)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmis = dict(sorted(gram2_pmi.items(), key=operator.itemgetter(1), reverse=True))\n",
    "list(pmis.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w',\n",
       " 'umowie',\n",
       " 'leasingu',\n",
       " 'zastrzeżono,',\n",
       " 'że',\n",
       " 'korzy',\n",
       " 'stający',\n",
       " 'będzie',\n",
       " 'ponosił',\n",
       " 'ciężar',\n",
       " 'tych',\n",
       " 'podatków',\n",
       " 'i',\n",
       " 'składek',\n",
       " 'niezależnie',\n",
       " 'od',\n",
       " 'opłat',\n",
       " 'za',\n",
       " 'używanie,',\n",
       " '3)',\n",
       " 'kaucji',\n",
       " 'określonej',\n",
       " 'w',\n",
       " 'umowie']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unfortunatelly some words are separated by new line and it was not possible to merge them together \"korzy\" \"stający\"\n",
    "\"\"\"             środków trwałych, jeżeli w umowie leasingu zastrzeżono, że korzy\n",
    "             stający będzie ponosił ciężar tych podatków i składek niezależnie\"\"\"\n",
    "old_tokens_list.index(\"korzy\")\n",
    "old_tokens_list[22536:22560]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tery', 'torialnego']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separate_puctuations([\"tery­torialnego\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Sort the word pairs according to that measure in the descending order and determine top 10 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Filter bigrams with number of occurrences lower than 5. Determine top 10 entries for the remaining dataset (>=5\n",
    "   occurrences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w art', 32045),\n",
       " ('mowa w', 28471),\n",
       " ('w ust', 23557),\n",
       " ('o których', 13885),\n",
       " ('których mowa', 13858),\n",
       " ('otrzymuje brzmienie', 9553),\n",
       " ('z dnia', 9527),\n",
       " ('o którym', 9184),\n",
       " ('którym mowa', 9171),\n",
       " ('do spraw', 8718)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram2_pmi5 = {k: v for k, v in Counter(gram2).items() if v >= 5}\n",
    "gram2_pmi5 = dict(sorted(gram2_pmi5.items(), key=operator.itemgetter(1), reverse=True))\n",
    "list(gram2_pmi5.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use [log likelihood ratio](http://tdunning.blogspot.com/2008/03/surprise-and-coincidence.html) (LLR) to compute the measure\n",
    "   for all pairs of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram2_count = Counter(gram2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # How LLR algorithm should look like, but this implementation is too slow\n",
    "def H(k):\n",
    "    # print(k)\n",
    "    N = np.sum(k)\n",
    "    # print(N)\n",
    "    # print(np.sum(k/N * np.ma.log(k/N).filled(0)))\n",
    "    return np.sum(k/N * np.ma.log(k/N).filled(0))\n",
    "\n",
    "\n",
    "def llr(a,b):\n",
    "\n",
    "    k11 = gram2_count[a+' '+b]\n",
    "    k12 = sum([count for key, count in gram2_count.items() if not a in key and b in key])\n",
    "    k21 = sum([count for key, count in gram2_count.items() if a in key and not b in key])\n",
    "    k22 = sum([count for key, count in gram2_count.items() if not a in key and not b in key])\n",
    "    k = np.array([[k11,k12],[k21,k22]])\n",
    "    rowSums = np.sum(k, axis=1).tolist()\n",
    "    colSums = np.sum(k, axis=0).tolist()\n",
    "    \n",
    "    return 2* np.sum(k) * (H(k) - H(rowSums) - H(colSums))    \n",
    "\n",
    "\n",
    "llr('w','art2')\n",
    "\n",
    "bigram_llr =  {}\n",
    "length = len(gram2)\n",
    "i=0 \n",
    "for key in gram2:\n",
    "    if len(key.split())>2:\n",
    "        print(key)\n",
    "    bigram_llr[key] = llr(*key.split())\n",
    "    if i%10==0:\n",
    "        print(f'{i}/{length}')\n",
    "    print(key,bigram_llr[key])\n",
    "    i+=1\n",
    "    \n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "token_count = defaultdict(int)\n",
    "\n",
    "for bigram, count in gram2_count.items():\n",
    "    (first_token, second_token) = bigram.split()\n",
    "    token_count[first_token] += count\n",
    "    token_count[second_token] += count\n",
    "\n",
    "total = sum(gram2_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72556.59014900832"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def H(k):\n",
    "    N = np.sum(k)\n",
    "    return np.sum(k / N * np.ma.log(k / N).filled(0))\n",
    "\n",
    "\n",
    "def llr(a, b):\n",
    "\n",
    "    k11 = gram2_count[a + \" \" + b]\n",
    "    k12 = token_count[b] - k11\n",
    "    k21 = token_count[a] - k11\n",
    "    k22 = total - k21 - k12 - k11\n",
    "    k = np.array([[k11, k12], [k21, k22]])\n",
    "    rowSums = np.sum(k, axis=1).tolist()\n",
    "    colSums = np.sum(k, axis=0).tolist()\n",
    "\n",
    "    return 2 * np.sum(k) * (H(k) - H(rowSums) - H(colSums))\n",
    "\n",
    "\n",
    "llr(\"w\", \"art\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2837496\n",
      "283749/2837496\n",
      "567498/2837496\n",
      "851247/2837496\n",
      "1134996/2837496\n",
      "1418745/2837496\n",
      "1702494/2837496\n",
      "1986243/2837496\n",
      "2269992/2837496\n",
      "2553741/2837496\n",
      "2837490/2837496\n"
     ]
    }
   ],
   "source": [
    "gram2_llr = {}\n",
    "length = len(gram2)\n",
    "i = 0\n",
    "for key in gram2:\n",
    "    if len(key.split()) > 2:\n",
    "        print(key)\n",
    "    gram2_llr[key] = llr(*key.split())\n",
    "    if i % (int(length / 10)) == 0:\n",
    "        print(f\"{i}/{length}\")\n",
    "    # print(key,gram2_llr[key])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Sort the word pairs according to that measure in the descending order and display top 10 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('otrzymuje brzmienie', 102885.48395536352),\n",
       " ('w w', 88950.24561342891),\n",
       " ('w art', 72556.59014900832),\n",
       " ('których mowa', 65874.30552844425),\n",
       " ('w ust', 59140.47968532207),\n",
       " ('o których', 52416.33194280648),\n",
       " ('mowa w', 51071.7654550929),\n",
       " ('drodze rozporządzenia', 45996.84967469449),\n",
       " ('dodaje się', 43483.15738019904),\n",
       " ('którym mowa', 42425.906420601474)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram2_llr = dict(sorted(gram2_llr.items(), key=operator.itemgetter(1), reverse=True))\n",
    "list(gram2_llr.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gram2_llr5 = {k: v for k, v in Counter(gram2).items() if v >= 5}\n",
    "gram2_llr5 = dict(sorted(gram2_llr5.items(), key=operator.itemgetter(1), reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Compute **trigram** counts for the whole corpus and perform the same filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The quick brown', 'quick brown fox', 'brown fox jumps', 'fox jumps over', 'jumps over the', 'over the lazy', 'the lazy dog.']\n"
     ]
    }
   ],
   "source": [
    "def trigrams(words):\n",
    "    words = list(map(lambda x: x.strip(), words))\n",
    "    words = zip(words, words[1:], words[2:])\n",
    "    return [\" \".join(pair) for pair in words]\n",
    "\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "words = [token.text for token in tokenizer(text)]\n",
    "print(trigrams(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram3 = trigrams(tokens_list)\n",
    "gram3 = [\n",
    "    token\n",
    "    for token in gram3\n",
    "    if all(char not in string.punctuation and not char.isdigit() for char in token)\n",
    "]\n",
    "# gram3 = [ k for k, v in Counter(gram3).items() if v>=5] # filter with treshold = 5 (minimum 5 occurrences of the phrase)\n",
    "\n",
    "gram3_count = Counter(gram3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Use PMI (with 5 occurrence threshold) and LLR to compute top 10 results for the trigrams. Devise a method for computing the values, based on the\n",
    "   results for bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_probabilities(tokens):\n",
    "    tokens_count = Counter(tokens)\n",
    "    count = sum(tokens_count.values())\n",
    "    return {k: v / count for k, v in tokens_count.items()}\n",
    "\n",
    "\n",
    "p_gram3 = to_probabilities(gram3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi3(x, y, z):  # pointwise_mutual_information\n",
    "    result = p_gram3[x + \" \" + y + \" \" + z] / (p_token[x] * p_token[y] * p_token[z])\n",
    "    return math.log2(result)\n",
    "\n",
    "\n",
    "gram3_pmi = {}\n",
    "for key in gram3:\n",
    "    if len(key.split()) != 3:\n",
    "        print(key)\n",
    "    gram3_pmi[key] = pmi3(*key.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ustawa z dnia', 13.618171861614767),\n",
       " ('o zmianie ustawy', 15.025339449632657),\n",
       " ('zmianie ustawy o', 14.622148193201921),\n",
       " ('ustawy o systemie', 12.351357582605694),\n",
       " ('o systemie oświaty', 17.44810027180696),\n",
       " ('systemie oświaty art', 12.887433565421388),\n",
       " ('w ustawie z', 10.98642798376495),\n",
       " ('ustawie z dnia', 14.474564547577835),\n",
       " ('systemie oświaty dz', 19.03142976020336),\n",
       " ('wprowadza się następujące', 18.73874440666137)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gram3_pmi.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram3_pmi5 = {k: v for k, v in Counter(gram3).items() if v >= 5}\n",
    "gram3_pmi5 = dict(sorted(gram3_pmi5.items(), key=operator.itemgetter(1), reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "Regarding trigrams, one of the easiest implementations is to simply make a pass looking for significant bigrams. Then, considering those bigrams as single words, make another pass looking for bigrams that include bigrams from the first pass. These composite bigrams are really trigrams. You can repeat this process as you like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "token_count = defaultdict(int)\n",
    "\n",
    "\n",
    "for trigram, count in gram3_count.items():\n",
    "    (a, b, c) = trigram.split()\n",
    "    first_token = a + \" \" + b\n",
    "    second_token = b + \" \" + c\n",
    "    token_count[first_token] += count\n",
    "    token_count[second_token] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2353306\n"
     ]
    }
   ],
   "source": [
    "total = len(gram3)\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(k):\n",
    "    # print(k)\n",
    "\n",
    "    N = np.sum(k)\n",
    "    # print(N)\n",
    "    # print(np.sum(k/N * np.ma.log(k/N).filled(0)))\n",
    "    return np.sum(k / N * np.ma.log(k / N).filled(0))\n",
    "\n",
    "\n",
    "def llr3(a, b, trigram):\n",
    "\n",
    "    k11 = gram3_count[trigram]\n",
    "    k12 = token_count[b] - k11\n",
    "    k21 = token_count[a] - k11\n",
    "    k22 = total - k21 - k12 - k11\n",
    "    k = np.array([[k11, k12], [k21, k22]])\n",
    "    rowSums = np.sum(k, axis=1).tolist()\n",
    "    colSums = np.sum(k, axis=0).tolist()\n",
    "\n",
    "    return 2 * np.sum(k) * (H(k) - H(rowSums) - H(colSums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/2353306\n",
      "235330/2353306\n",
      "470660/2353306\n",
      "705990/2353306\n",
      "941320/2353306\n",
      "1176650/2353306\n",
      "1411980/2353306\n",
      "1647310/2353306\n",
      "1882640/2353306\n",
      "2117970/2353306\n",
      "2353300/2353306\n"
     ]
    }
   ],
   "source": [
    "gram3_llr = {}\n",
    "length = len(gram3)\n",
    "i = 0\n",
    "for key in gram3:\n",
    "    if len(key.split()) != 3:\n",
    "        print(key)\n",
    "    (word1, word2, word3) = key.split()\n",
    "\n",
    "    first_token = f\"{word1} {word2}\"\n",
    "    second_token = f\"{word2} {word3}\"\n",
    "\n",
    "    gram3_llr[key] = llr3(first_token, second_token, key)\n",
    "\n",
    "    if i % (int(length / 10)) == 0:\n",
    "        print(f\"{i}/{length}\")\n",
    "    # print(key,gram2_llr[key])\n",
    "    i += 1\n",
    "\n",
    "# gram3_llr =dict(sorted(gram3_llr.items(), key=lambda item: item[1],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('o których mowa', 130326.30749652752),\n",
       " ('o którym mowa', 93966.98951460843),\n",
       " ('mowa w ust', 80683.70742976072),\n",
       " ('mowa w art', 70985.86883561742),\n",
       " ('których mowa w', 69167.67451145055),\n",
       " ('o której mowa', 61914.80145216781),\n",
       " ('w drodze rozporządzenia', 55068.65940835584),\n",
       " ('minister właściwy do', 47977.772785700996),\n",
       " ('którym mowa w', 45011.20512861168),\n",
       " ('w ustawie z', 35392.380207012866)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(gram3_llr.items(), key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram3_llr5 = {k: v for k, v in Counter(gram3).items() if v >= 5}\n",
    "gram3_llr5 = dict(sorted(gram3_llr5.items(), key=operator.itemgetter(1), reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Create a table comparing the methods (separate table for bigrams and trigrams)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ustawa z', 5.24992414625927),\n",
       " ('z dnia', 5.778516878792047),\n",
       " ('o zmianie', 6.81580808417473),\n",
       " ('zmianie ustawy', 8.510678895092788),\n",
       " ('ustawy o', 3.8602631638142415),\n",
       " ('o systemie', 5.968833836638906),\n",
       " ('systemie oświaty', 10.989844384358635),\n",
       " ('oświaty art', -0.29315970870050306),\n",
       " ('w ustawie', 5.324952584311153),\n",
       " ('ustawie z', 6.114202585886397)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gram2_pmi.items())[0:10]\n",
    "# table_trigrams_llr = copy.deepcopy(sorted(gram3_llr.items(), key=lambda x: -x[1]))\n",
    "# table_trigrams_pmi = copy.deepcopy(sorted(gram3_pmi.items(), key=lambda x: -x[1]))\n",
    "# table_bigrams_llr = copy.deepcopy(sorted(gram2_llr.items(), key=lambda x: -x[1]))\n",
    "# table_bigrams_pmi = copy.deepcopy(sorted(gram2_pmi.items(), key=lambda x: -x[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram2_pmi</th>\n",
       "      <th>gram2_pmi5</th>\n",
       "      <th>gram2_llr</th>\n",
       "      <th>gram2_llr5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ustawa z, 5.24992414625927)</td>\n",
       "      <td>(w art, 32045)</td>\n",
       "      <td>(otrzymuje brzmienie, 102885.48395536352)</td>\n",
       "      <td>(otrzymuje brzmienie, 102885.48395536352)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(z dnia, 5.778516878792047)</td>\n",
       "      <td>(mowa w, 28471)</td>\n",
       "      <td>(w w, 88950.24561342891)</td>\n",
       "      <td>(w w, 88950.24561342891)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(o zmianie, 6.81580808417473)</td>\n",
       "      <td>(w ust, 23557)</td>\n",
       "      <td>(w art, 72556.59014900832)</td>\n",
       "      <td>(w art, 72556.59014900832)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(zmianie ustawy, 8.510678895092788)</td>\n",
       "      <td>(o których, 13885)</td>\n",
       "      <td>(których mowa, 65874.30552844425)</td>\n",
       "      <td>(których mowa, 65874.30552844425)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(ustawy o, 3.8602631638142415)</td>\n",
       "      <td>(których mowa, 13858)</td>\n",
       "      <td>(w ust, 59140.47968532207)</td>\n",
       "      <td>(w ust, 59140.47968532207)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(o systemie, 5.968833836638906)</td>\n",
       "      <td>(otrzymuje brzmienie, 9553)</td>\n",
       "      <td>(o których, 52416.33194280648)</td>\n",
       "      <td>(o których, 52416.33194280648)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(systemie oświaty, 10.989844384358635)</td>\n",
       "      <td>(z dnia, 9527)</td>\n",
       "      <td>(mowa w, 51071.7654550929)</td>\n",
       "      <td>(mowa w, 51071.7654550929)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(oświaty art, -0.29315970870050306)</td>\n",
       "      <td>(o którym, 9184)</td>\n",
       "      <td>(drodze rozporządzenia, 45996.84967469449)</td>\n",
       "      <td>(drodze rozporządzenia, 45996.84967469449)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(w ustawie, 5.324952584311153)</td>\n",
       "      <td>(którym mowa, 9171)</td>\n",
       "      <td>(dodaje się, 43483.15738019904)</td>\n",
       "      <td>(dodaje się, 43483.15738019904)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(ustawie z, 6.114202585886397)</td>\n",
       "      <td>(do spraw, 8718)</td>\n",
       "      <td>(którym mowa, 42425.906420601474)</td>\n",
       "      <td>(którym mowa, 42425.906420601474)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                gram2_pmi                   gram2_pmi5  \\\n",
       "0            (ustawa z, 5.24992414625927)               (w art, 32045)   \n",
       "1             (z dnia, 5.778516878792047)              (mowa w, 28471)   \n",
       "2           (o zmianie, 6.81580808417473)               (w ust, 23557)   \n",
       "3     (zmianie ustawy, 8.510678895092788)           (o których, 13885)   \n",
       "4          (ustawy o, 3.8602631638142415)        (których mowa, 13858)   \n",
       "5         (o systemie, 5.968833836638906)  (otrzymuje brzmienie, 9553)   \n",
       "6  (systemie oświaty, 10.989844384358635)               (z dnia, 9527)   \n",
       "7     (oświaty art, -0.29315970870050306)             (o którym, 9184)   \n",
       "8          (w ustawie, 5.324952584311153)          (którym mowa, 9171)   \n",
       "9          (ustawie z, 6.114202585886397)             (do spraw, 8718)   \n",
       "\n",
       "                                    gram2_llr  \\\n",
       "0   (otrzymuje brzmienie, 102885.48395536352)   \n",
       "1                    (w w, 88950.24561342891)   \n",
       "2                  (w art, 72556.59014900832)   \n",
       "3           (których mowa, 65874.30552844425)   \n",
       "4                  (w ust, 59140.47968532207)   \n",
       "5              (o których, 52416.33194280648)   \n",
       "6                  (mowa w, 51071.7654550929)   \n",
       "7  (drodze rozporządzenia, 45996.84967469449)   \n",
       "8             (dodaje się, 43483.15738019904)   \n",
       "9           (którym mowa, 42425.906420601474)   \n",
       "\n",
       "                                   gram2_llr5  \n",
       "0   (otrzymuje brzmienie, 102885.48395536352)  \n",
       "1                    (w w, 88950.24561342891)  \n",
       "2                  (w art, 72556.59014900832)  \n",
       "3           (których mowa, 65874.30552844425)  \n",
       "4                  (w ust, 59140.47968532207)  \n",
       "5              (o których, 52416.33194280648)  \n",
       "6                  (mowa w, 51071.7654550929)  \n",
       "7  (drodze rozporządzenia, 45996.84967469449)  \n",
       "8             (dodaje się, 43483.15738019904)  \n",
       "9           (którym mowa, 42425.906420601474)  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "\t'gram2_pmi' : list(gram2_pmi.items())[0:10],\n",
    "    'gram2_pmi5' : list(gram2_pmi5.items())[0:10],\n",
    "    'gram2_llr' : list(gram2_llr.items())[0:10],\n",
    "    'gram2_llr5' : list(gram2_llr.items())[0:10]\n",
    "    \n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram3_pmi</th>\n",
       "      <th>gram3_pmi5</th>\n",
       "      <th>gram3_llr</th>\n",
       "      <th>gram3_llr5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ustawa z dnia, 13.618171861614767)</td>\n",
       "      <td>(o których mowa, 13857)</td>\n",
       "      <td>(ustawa z dnia, 11723.890826881581)</td>\n",
       "      <td>(ustawa z dnia, 11723.890826881581)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(o zmianie ustawy, 15.025339449632657)</td>\n",
       "      <td>(których mowa w, 13807)</td>\n",
       "      <td>(o zmianie ustawy, 10412.558289219796)</td>\n",
       "      <td>(o zmianie ustawy, 10412.558289219796)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(zmianie ustawy o, 14.622148193201921)</td>\n",
       "      <td>(mowa w ust, 13474)</td>\n",
       "      <td>(zmianie ustawy o, 6715.355207537126)</td>\n",
       "      <td>(zmianie ustawy o, 6715.355207537126)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(ustawy o systemie, 12.351357582605694)</td>\n",
       "      <td>(mowa w art, 12311)</td>\n",
       "      <td>(ustawy o systemie, 434.20969140718904)</td>\n",
       "      <td>(ustawy o systemie, 434.20969140718904)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(o systemie oświaty, 17.44810027180696)</td>\n",
       "      <td>(o którym mowa, 9169)</td>\n",
       "      <td>(o systemie oświaty, 1096.175919315129)</td>\n",
       "      <td>(o systemie oświaty, 1096.175919315129)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(systemie oświaty art, 12.887433565421388)</td>\n",
       "      <td>(którym mowa w, 9147)</td>\n",
       "      <td>(systemie oświaty art, 78.80874121247743)</td>\n",
       "      <td>(systemie oświaty art, 78.80874121247743)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(w ustawie z, 10.98642798376495)</td>\n",
       "      <td>(o której mowa, 5511)</td>\n",
       "      <td>(w ustawie z, 35392.380207012866)</td>\n",
       "      <td>(w ustawie z, 35392.380207012866)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(ustawie z dnia, 14.474564547577835)</td>\n",
       "      <td>(której mowa w, 5488)</td>\n",
       "      <td>(ustawie z dnia, 31925.559946377118)</td>\n",
       "      <td>(ustawie z dnia, 31925.559946377118)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(systemie oświaty dz, 19.03142976020336)</td>\n",
       "      <td>(w drodze rozporządzenia, 4691)</td>\n",
       "      <td>(systemie oświaty dz, 597.8913321280303)</td>\n",
       "      <td>(systemie oświaty dz, 597.8913321280303)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(wprowadza się następujące, 18.73874440666137)</td>\n",
       "      <td>(właściwy do spraw, 4620)</td>\n",
       "      <td>(wprowadza się następujące, 23727.611179452793)</td>\n",
       "      <td>(wprowadza się następujące, 23727.611179452793)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        gram3_pmi  \\\n",
       "0             (ustawa z dnia, 13.618171861614767)   \n",
       "1          (o zmianie ustawy, 15.025339449632657)   \n",
       "2          (zmianie ustawy o, 14.622148193201921)   \n",
       "3         (ustawy o systemie, 12.351357582605694)   \n",
       "4         (o systemie oświaty, 17.44810027180696)   \n",
       "5      (systemie oświaty art, 12.887433565421388)   \n",
       "6                (w ustawie z, 10.98642798376495)   \n",
       "7            (ustawie z dnia, 14.474564547577835)   \n",
       "8        (systemie oświaty dz, 19.03142976020336)   \n",
       "9  (wprowadza się następujące, 18.73874440666137)   \n",
       "\n",
       "                        gram3_pmi5  \\\n",
       "0          (o których mowa, 13857)   \n",
       "1          (których mowa w, 13807)   \n",
       "2              (mowa w ust, 13474)   \n",
       "3              (mowa w art, 12311)   \n",
       "4            (o którym mowa, 9169)   \n",
       "5            (którym mowa w, 9147)   \n",
       "6            (o której mowa, 5511)   \n",
       "7            (której mowa w, 5488)   \n",
       "8  (w drodze rozporządzenia, 4691)   \n",
       "9        (właściwy do spraw, 4620)   \n",
       "\n",
       "                                         gram3_llr  \\\n",
       "0              (ustawa z dnia, 11723.890826881581)   \n",
       "1           (o zmianie ustawy, 10412.558289219796)   \n",
       "2            (zmianie ustawy o, 6715.355207537126)   \n",
       "3          (ustawy o systemie, 434.20969140718904)   \n",
       "4          (o systemie oświaty, 1096.175919315129)   \n",
       "5        (systemie oświaty art, 78.80874121247743)   \n",
       "6                (w ustawie z, 35392.380207012866)   \n",
       "7             (ustawie z dnia, 31925.559946377118)   \n",
       "8         (systemie oświaty dz, 597.8913321280303)   \n",
       "9  (wprowadza się następujące, 23727.611179452793)   \n",
       "\n",
       "                                        gram3_llr5  \n",
       "0              (ustawa z dnia, 11723.890826881581)  \n",
       "1           (o zmianie ustawy, 10412.558289219796)  \n",
       "2            (zmianie ustawy o, 6715.355207537126)  \n",
       "3          (ustawy o systemie, 434.20969140718904)  \n",
       "4          (o systemie oświaty, 1096.175919315129)  \n",
       "5        (systemie oświaty art, 78.80874121247743)  \n",
       "6                (w ustawie z, 35392.380207012866)  \n",
       "7             (ustawie z dnia, 31925.559946377118)  \n",
       "8         (systemie oświaty dz, 597.8913321280303)  \n",
       "9  (wprowadza się następujące, 23727.611179452793)  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "\t'gram3_pmi' : list(gram3_pmi.items())[0:10],\n",
    "    'gram3_pmi5' : list(gram3_pmi5.items())[0:10],\n",
    "    'gram3_llr' : list(gram3_llr.items())[0:10],\n",
    "    'gram3_llr5' : list(gram3_llr.items())[0:10]\n",
    "    \n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_trigrams5_llr = copy.deepcopy(sorted(gram3_llr.items(), key=lambda x: -x[1]))\n",
    "# table_trigrams5_pmi = copy.deepcopy(sorted(gram3_pmi.items(), key=lambda x: -x[1]))\n",
    "# table_bigrams5_llr = copy.deepcopy(sorted(gram2_llr.items(), key=lambda x: -x[1]))\n",
    "# table_bigrams5_pmi = copy.deepcopy(sorted(gram2_pmi.items(), key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Answer the following questions:\n",
    "\n",
    "   a. Why do we have to filter the bigrams, rather than the token sequence?\n",
    "   \n",
    "   b. Which measure (PMI, PMI with filtering, LLR) works better for the bigrams and which for the trigrams?\n",
    "   \n",
    "   c. What types of expressions are discovered by the methods.\n",
    "   \n",
    "   d. Can you devise a different type of filtering that would yield better results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml] *",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
